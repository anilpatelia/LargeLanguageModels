{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from transformers import WhisperProcessor, WhisperForConditionalGeneration\nfrom datasets import load_dataset\nimport torch\nimport torchaudio\nfrom transformers import WhisperProcessor, pipeline\nfrom datasets import load_dataset\nimport evaluate\nimport tempfile\nimport os\n\n","metadata":{"execution":{"iopub.status.busy":"2024-08-24T12:34:17.261456Z","iopub.execute_input":"2024-08-24T12:34:17.261885Z","iopub.status.idle":"2024-08-24T12:34:25.006637Z","shell.execute_reply.started":"2024-08-24T12:34:17.261840Z","shell.execute_reply":"2024-08-24T12:34:25.005158Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Step 1: Load the common_voice dataset for Tamil\ndataset = load_dataset(\"mozilla-foundation/common_voice_11_0\", \"mr\", split=\"test\", trust_remote_code=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-24T12:34:36.956883Z","iopub.execute_input":"2024-08-24T12:34:36.957648Z","iopub.status.idle":"2024-08-24T12:36:05.135818Z","shell.execute_reply.started":"2024-08-24T12:34:36.957598Z","shell.execute_reply":"2024-08-24T12:36:05.134650Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/8.13k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3942088922784de582906d3ae8149e1e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/14.4k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c8d789bfdd0b492bb0381d88b3568a7c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading extra modules:   0%|          | 0.00/3.44k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"700d2bb3bc844ff8b6ffbff8c137da81"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading extra modules:   0%|          | 0.00/60.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"70d4ef135033402c94b44215b20b5ccd"}},"metadata":{}},{"output_type":"stream","name":"stdin","text":"The repository for mozilla-foundation/common_voice_11_0 contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/mozilla-foundation/common_voice_11_0.\nYou can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n\nDo you wish to run the custom code? [y/N]  y\n"},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/12.2k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"69ac8f1cea154be08b391b1f03462cdd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/82.3M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed3da1250a074ea8b5a8f041ddbdff2c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/65.5M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"da571b54d4ef44e49e54edb0fdfe2b4f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/69.7M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"272dd068ac3d4e91af790bd516b31fb2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/110M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"06724f45b8a143e68154ae6882a2b1b5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/91.0M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc8c6269974c480db47ef9971755af63"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/782k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fa8f8beb473e4eb38b3f2f6482a27a83"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/581k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"40659fe6ebf44c7d9345c408a65d63ab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/616k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3fe3803c020e40d18f246657f5d8c259"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/974k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d99e2b28663c421f834b82edc8c2f20b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/789k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe8cd7f44a904a4dbc53eb07df51479d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"089cdbfbbd1e4d5abe1957760f992a07"}},"metadata":{}},{"name":"stderr","text":"\nReading metadata...: 2245it [00:00, 110367.37it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating validation split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4ce1e21e0981431dbde9fb86a4dbf45b"}},"metadata":{}},{"name":"stderr","text":"\nReading metadata...: 1682it [00:00, 94826.66it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating test split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b22c5eb5d7864fd38c5711aeefc506de"}},"metadata":{}},{"name":"stderr","text":"\nReading metadata...: 1816it [00:00, 78261.27it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating other split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1810c76a9e6547a1a026ecba65c30832"}},"metadata":{}},{"name":"stderr","text":"\nReading metadata...: 2819it [00:00, 108497.60it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating invalidated split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d50a3c470d34e26ac7a52490646c5ed"}},"metadata":{}},{"name":"stderr","text":"\nReading metadata...: 2237it [00:00, 117189.47it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"import torchaudio\n\ndef speech_file_to_array_fn(batch):\n    speech_array, sampling_rate = torchaudio.load(batch[\"path\"])\n    batch[\"speech\"] = speech_array[0].numpy()\n    batch[\"sampling_rate\"] = sampling_rate\n    batch[\"target_text\"] = batch[\"sentence\"]\n    return batch\n","metadata":{"execution":{"iopub.status.busy":"2024-08-24T12:37:33.196064Z","iopub.execute_input":"2024-08-24T12:37:33.196530Z","iopub.status.idle":"2024-08-24T12:37:33.888371Z","shell.execute_reply.started":"2024-08-24T12:37:33.196486Z","shell.execute_reply":"2024-08-24T12:37:33.887261Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"dataset = dataset.map(speech_file_to_array_fn, remove_columns=dataset.column_names)","metadata":{"execution":{"iopub.status.busy":"2024-08-24T12:37:35.033042Z","iopub.execute_input":"2024-08-24T12:37:35.033484Z","iopub.status.idle":"2024-08-24T12:37:54.130470Z","shell.execute_reply.started":"2024-08-24T12:37:35.033440Z","shell.execute_reply":"2024-08-24T12:37:54.129310Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1816 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f0ad5820be64abf9aa5f8461efcc138"}},"metadata":{}}]},{"cell_type":"code","source":"import librosa\nimport numpy as np\n\ndef resample(batch):\n    speech_array = np.asarray(batch[\"speech\"])\n    batch[\"speech\"] = librosa.resample(speech_array, orig_sr=48_000, target_sr=16_000)\n    batch[\"sampling_rate\"] = 16_000\n    return batch","metadata":{"execution":{"iopub.status.busy":"2024-08-24T12:37:25.050459Z","iopub.execute_input":"2024-08-24T12:37:25.050968Z","iopub.status.idle":"2024-08-24T12:37:25.065153Z","shell.execute_reply.started":"2024-08-24T12:37:25.050922Z","shell.execute_reply":"2024-08-24T12:37:25.063707Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"dataset = dataset.map(resample, num_proc=4)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"processor = WhisperProcessor.from_pretrained(\"openai/whisper-large\")\nmodel = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-large\")\nmodel.config.forced_decoder_ids = processor.get_decoder_prompt_ids(language=\"mr\", task=\"transcribe\")\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def transcribe(batch):\n    input_features = processor(batch[\"speech\"], sampling_rate=batch[\"sampling_rate\"], return_tensors=\"pt\").input_features \n\n    # generate token ids\n    with torch.no_grad():\n        predicted_ids = model.generate(input_features)\n    # decode token ids to text\n    #transcription = processor.batch_decode(predicted_ids, skip_special_tokens=False)\n    #print(transcription)\n    batch[\"transcription\"] = processor.batch_decode(predicted_ids, skip_special_tokens=True)\n    #print(transcription)\n    return batch","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}